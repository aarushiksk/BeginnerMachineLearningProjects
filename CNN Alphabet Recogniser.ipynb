{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb3b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb212b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb3e70a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, reload the dataset and change it into \"numpy array\".\n",
    "dataset = np.loadtxt('C:\\\\Users\\\\aarus\\\\Downloads\\\\archive\\\\A_Z Handwritten Data.csv', delimiter=',')\n",
    "#Dataset is split into 2 parts, training and testing...\n",
    "X = dataset[:,0:784]\n",
    "Y = dataset[:,0]\n",
    "#Split the \"X,Y\" data into the ratio of 7:3, 3 is the test size. \n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.3, random_state=2)\n",
    "#Reshape the data and change it into float 32 as usual.\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "#The pixel of the data is comprised from 0 to 255. 0 is white,255 is black.\n",
    "#Now normalize the data from 0 to 1 without some libraries, in a simple way.\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b249d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "#Classify 26 alphabets.\n",
    "num_classes = Y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd59bfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 26)                3354      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 594,138\n",
      "Trainable params: 594,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "#Choose an optimizer and compile the model.\n",
    "model.compile(optimizer = Adam(learning_rate = 0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#And print the summary of the model.\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf309600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2037/2037 [==============================] - 49s 23ms/step - loss: 0.1879 - accuracy: 0.9474\n",
      "Epoch 2/5\n",
      "2037/2037 [==============================] - 51s 25ms/step - loss: 0.0965 - accuracy: 0.9725\n",
      "Epoch 3/5\n",
      "2037/2037 [==============================] - 69s 34ms/step - loss: 0.0835 - accuracy: 0.9759\n",
      "Epoch 4/5\n",
      "2037/2037 [==============================] - 61s 30ms/step - loss: 0.0736 - accuracy: 0.9786\n",
      "Epoch 5/5\n",
      "2037/2037 [==============================] - 73s 36ms/step - loss: 0.0644 - accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "Train1=model.fit(X_train, Y_train,batch_size=128, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test1=model.fit(X_test, Y_test,batch_size=128, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca31f2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2581a11add0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[[20]].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a997fa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.4863365e-24, 2.7577325e-22, 3.0940535e-24, 9.5667434e-24,\n",
       "        5.6675716e-15, 2.7559205e-13, 2.6567584e-26, 8.0795123e-18,\n",
       "        4.7705072e-19, 8.7724161e-15, 1.8962131e-15, 8.5282072e-16,\n",
       "        2.8693107e-19, 2.0498952e-16, 2.2227371e-18, 5.1974731e-12,\n",
       "        1.7740156e-24, 5.3371663e-22, 2.8337836e-12, 2.0672633e-07,\n",
       "        4.2846456e-20, 4.5982154e-10, 3.2689482e-14, 3.7445014e-05,\n",
       "        9.9996233e-01, 1.6663498e-12]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=model.predict(X_test[[20]]) \n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89f73733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is Y\n"
     ]
    }
   ],
   "source": [
    "alphabets=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "list1=[]\n",
    "[list1.append(i) for i in range(26)]\n",
    "list2=[]\n",
    "[list2.append(i) for i in alphabets]\n",
    "dic = dict(zip(list1, list2))\n",
    "#Let's check the result.\n",
    "print(\"The answer is\",dic[np.argmax(prediction)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57d046ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'model_hand2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e987011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8097296c",
   "metadata": {},
   "source": [
    "# Ignore the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275932dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], 28,28))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], 28,28))\n",
    "\n",
    "print(\"Train data shape: \", train_x.shape)\n",
    "print(\"Test data shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
    "print(\"New shape of train data: \", train_X.shape)\n",
    "\n",
    "test_X = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2],1)\n",
    "print(\"New shape of train data: \", test_X.shape)\n",
    "\n",
    "#Now we reshape the train & test image dataset so that they can be put in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "\n",
    "model.add(Dense(26,activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yOHE = to_categorical(train_y, num_classes = 26, dtype='int')\n",
    "print(\"New shape of train labels: \", train_yOHE.shape)\n",
    "\n",
    "test_yOHE = to_categorical(test_y, num_classes = 26, dtype='int')\n",
    "print(\"New shape of test labels: \", test_yOHE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_X, train_yOHE, epochs=1,  validation_data = (test_X,test_yOHE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d829456",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_X, train_yOHE, epochs=2, batch_size=32, validation_data=(test_X,test_yOHE))\n",
    "\n",
    "# Evaluate the model on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731c9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9010f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91564d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(test_y, np.argmax(predictions, axis=1))\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d8358",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'model_hand1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c14184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b906dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(\"C:\\\\Users\\\\aarus\\\\model_hand1.h5\")\n",
    "\n",
    "\n",
    "canvas_size = 200\n",
    "canvas = np.zeros((canvas_size, canvas_size), dtype=np.uint8)\n",
    "drawing = False\n",
    "\n",
    "\n",
    "def draw(event, x, y, flags, param):\n",
    "    global canvas, drawing\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        cv2.circle(canvas, (x, y), 10, 255, -1)  # Draw a white circle on click\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            cv2.circle(canvas, (x, y), 10, 255, -1)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "\n",
    "# Set up OpenCV window\n",
    "cv2.namedWindow('Draw Alphabet')\n",
    "cv2.setMouseCallback('Draw Alphabet', draw)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('Draw Alphabet', canvas)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "    elif key == ord('p'):  # Press 'p' to predict\n",
    "        # Preprocess drawn image\n",
    "        resized_img = cv2.resize(canvas, (28, 28))\n",
    "        normalized_img = resized_img / 255.0\n",
    "        input_img = np.expand_dims(normalized_img, axis=0)\n",
    "        \n",
    "        # Make prediction\n",
    "        predictions = model.predict(input_img)\n",
    "        predicted_class = np.argmax(predictions)\n",
    "        predicted_alphabet = chr(ord('A') + predicted_class)\n",
    "        \n",
    "        print(f'Predicted alphabet: {predicted_alphabet}')\n",
    "        \n",
    "        result_display = np.ones((canvas_size, canvas_size), dtype=np.uint8) * 255\n",
    "        cv2.putText(result_display, f'Predicted: {predicted_alphabet}', (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.8, 0, 2)\n",
    "        cv2.imshow('Draw Alphabet', result_display)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83a6dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955be9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e815b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8094a73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eec23138",
   "metadata": {},
   "source": [
    "# Use this code to use openCV for entering an alphabet as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88a14bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Preprocessing is completed\n",
      "Starting to make prediction\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "The answer is b\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf  # Import TensorFlow for model loading and predictions\n",
    "\n",
    "# Load your saved model\n",
    "model = tf.keras.models.load_model(\"C:\\\\Users\\\\aarus\\\\model_hand2.h5\")\n",
    "\n",
    "canvas_size = 400\n",
    "canvas = np.zeros((canvas_size, canvas_size), dtype=np.uint8) * 255  # Initialize canvas as white\n",
    "drawing = False\n",
    "font_scale = 2\n",
    "font_thickness = 3\n",
    "text_color = (255, 255, 255)  # Black color for drawing text\n",
    "\n",
    "def draw_alphabet(event, x, y, flags, param):\n",
    "    global canvas, drawing\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            cv2.circle(canvas, (x, y), 10, text_color, -1)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        cv2.circle(canvas, (x, y), 10, text_color, -1)\n",
    "\n",
    "cv2.namedWindow('Whiteboard')\n",
    "cv2.setMouseCallback('Whiteboard', draw_alphabet)\n",
    "resized_img = 0\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('Whiteboard', canvas)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "    if key == ord('r'):  # If 'p' is pressed, perform input image preprocessing\n",
    "        if resized_img is not None:\n",
    "            # Perform prediction\n",
    "            resized_img = cv2.resize(canvas_copy, (28, 28))\n",
    "            normalized_img = resized_img / 255.0\n",
    "            input_img = np.expand_dims(normalized_img, axis=-1)\n",
    "            input_img = np.expand_dims(input_img, axis=0)  # Add batch dimension\n",
    "            print(\"Image Preprocessing is completed\")\n",
    "            \n",
    "           \n",
    "            \n",
    "    elif key == ord('s'):  # Press 's' to save the snapshot and make predictions\n",
    "        if resized_img is not None:\n",
    "             # Make predictions using your model\n",
    "            print(\"Starting to make prediction\")\n",
    "            predictions = model.predict(input_img)\n",
    "            \n",
    "            \n",
    "            alphabets=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "            list1=[]\n",
    "            [list1.append(i) for i in range(26)]\n",
    "            list2=[]\n",
    "            [list2.append(i) for i in alphabets]\n",
    "            dic = dict(zip(list1, list2))\n",
    "            #Let's check the result.\n",
    "            print(\"The answer is\",dic[np.argmax(predictions)])\n",
    "            cv2.imwrite('drawing_snapshot.png', resized_img)  # Save the snapshot as 'drawing_snapshot.png'\n",
    "    \n",
    "    # Create an image of the current canvas\n",
    "    canvas_copy = canvas.copy()\n",
    "\n",
    "    # Display the image of the current canvas\n",
    "    cv2.imshow('Drawing Snapshot', canvas_copy)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593efe6c",
   "metadata": {},
   "source": [
    "# Use the below code to check the input image being fed for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd5201fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Assuming input_img is your 4D array (shape: (1, 28, 28, 1))\n",
    "\n",
    "# Remove the batch dimension\n",
    "image_3d = input_img[0]\n",
    "\n",
    "# Remove the channel dimension (assuming it's grayscale)\n",
    "image_2d = image_3d[:, :, 0]\n",
    "\n",
    "# Rescale pixel values to the original range (0 to 255)\n",
    "rescaled_image = (image_2d * 255).astype(np.uint8)\n",
    "\n",
    "# Create a blank 200x200 canvas\n",
    "canvas = np.ones((200, 200), dtype=np.uint8) * 255  # Initialize canvas as white\n",
    "\n",
    "# Calculate the position to place the input image at the center of the canvas\n",
    "x_offset = (canvas.shape[1] - rescaled_image.shape[1]) // 2\n",
    "y_offset = (canvas.shape[0] - rescaled_image.shape[0]) // 2\n",
    "\n",
    "# Copy the input image onto the canvas\n",
    "canvas[y_offset:y_offset + rescaled_image.shape[0], x_offset:x_offset + rescaled_image.shape[1]] = rescaled_image\n",
    "\n",
    "# Display the canvas with the input image\n",
    "cv2.imshow('Input Image on Canvas', canvas)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Optionally, you can save the canvas as a file\n",
    "cv2.imwrite('input_image_on_canvas.png', canvas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28971bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8f1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86b205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dc5baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b21f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cfed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98166e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape,X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af24c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=X_train[0:180000]\n",
    "train_Y=y_train[0:180000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36af3b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b9ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f21e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db598c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8346278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc= accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb170339",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c863bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
